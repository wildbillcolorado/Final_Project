{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project GEOL 5042\n",
    "\n",
    "# ***Applications of Eye-Tracking in Geology Discipline-Based Education Research (GeoDBER)***\n",
    "\n",
    "### By: William Bennett"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "As a first-year master student, I'll be tackling 2 research projects based on GeoDBER, specifically regarding the applications of eye tracking in the field. My first project is a literature review that seeks to answer the question of how has eye-tracking been used to study how students approach interpretting and processing visual representations of scientific (with an emphasis on geo-scientific) data. My next project may or may not involve data collection (due to Covid), but will certainly involve parsing, organizing, and analyzing large swathes of eye movement data. There are many aspects of my resarch that are still not set in stone - which software/hardware I'll be working with, or even what specific research questions I'll be asking. \n",
    "\n",
    "I find that many of the tools and methods this class teaches will be significantly more applicable to my second research project compared to my current one, and because I do not have a complete data set for either project, I will be using small manufactured data sets. It's my hope that these applications will be able to easily scale/transfer to the completed data sets I'll be working with. \n",
    "\n",
    "I find working in python is a lot more comfortable for me, but I figured it would be benficial to get more experience in R, so\n",
    "every exercise I did for this project was in r.\n",
    "\n",
    "\n",
    "# Background\n",
    "\n",
    "Implementations of eye-tracking in education research is a relatively new trend, with an explosion in popularity within the last 2 decades. Because of the field's infancy, there are few theoretical frameworks that are widely \n",
    "\n",
    "When we buckle down to concentrate on a cognitively taxing task in front of us, like when we take a test or read a page, our eyes do not move in a continously smooth motion. Instead our eyes alternate between short rapid movements (saccades) and short stops (fixations). Modern eye-tracking research typically involves a screen and a capture device, usually in the form of a sensor fixated a few feet away from a participant's face that captures eye movements on a computer screen. Typically the screen will be divided into areas of interest (AOI's), and at a sampling rate that is typically 30-200 hz, the most common parameters that are captured are:\n",
    "\n",
    "* Pupil Diameter\n",
    "* Focus x-position\n",
    "* Focus y-position\n",
    "* Time\n",
    "\n",
    "\n",
    "\n",
    "<center> \n",
    "\n",
    "    Heat Map Example:\n",
    "![alt text](Eye_Tracking_Heat_Map.png)\n",
    "\n",
    "    Scan Path Example:\n",
    "![alt text](Eye_Tracking_ScanPath.jpg)\n",
    "\n",
    "    Typical Sensor/Screen Apparatus:\n",
    "![alt text](Eye_Tracking_Aparatus.jpg)\n",
    "\n",
    "</center>\n",
    "\n",
    "Companies that sell eye tracking hardware also commonly sell software packages to be included. These software packages offer a miriad of data visualization options, from heat/topology maps to fixation sequencing. These software packages come with more features than I can think to make for anlayzing eye-movement data, so I don't think it would be particularly useful to try and create tools that are beyond the capabilities of these packages.\n",
    "\n",
    "One particularly interesting tool I've found online for free is the eyetrackingR package\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Research Project: Intergrative Literature Review\n",
    "\n",
    "\n",
    "To give some background on this literature review, there were 33 articles that were read which all included a combination of eye-tracking parameters being recorded, mentions visual representations of data that were related to a STEM field (chemistry,physics, geology, biology for this review), with an application towards education.\n",
    "\n",
    "A coding manual was used to organize and quantify aspects of these articles, with the following parameters being recorded:\n",
    "\n",
    "* Type of eye-movement paramter tracked (saccade, fixation number, scan path, etc.)\n",
    "* What type of visual data does study use (maps, 2D graphs, 3D graphs, diagrams, etc.) \n",
    "* What demographic of learners (Undergrad Science majors, Undergrad non-science majors, Graduate students, etc.)\n",
    "* What components of media cognition are explored (Visual placement, Pre-Training content, Signaling, Expertise effect, etc))\n",
    "* Does study observe method/parameter that leads to better performance (coded Y/N)\n",
    "* Is study exploratory or applied (Y/N)\n",
    "* Does study explicitly use a theoretical framework to scaffold its questions. (Y/N)\n",
    "* ...and some other parameters\n",
    "\n",
    "\n",
    "With this data set I'm wanting to identify trends in the current DBER literature regarding eye tracking and visual representations in STEM. The **types of questions** to ask with this data set seem to come in 2 major flavors:\n",
    "\n",
    "1: Does one parameter's frequency lead to another prameter's frequency? For example, do certain eye movement parameters lead to a higher rate of better performance (if so we should maybe focus on these eye tracking parameters in the future)?\n",
    "\n",
    "2: What are the proprtions of parameters in the current field? For example, what proportion of studies involve Undergrad students vs graduate students? What proportion are chemistry/physics/geology/etc.\n",
    "\n",
    "The **main goals** of this literature review are to\n",
    "\n",
    "1: Familiarize myself with eye tracking applications in STEM DBER fields.\n",
    "2: Provide a bit of a historic/macro scale review of the field as a resource for others.\n",
    "3: Provide insight into which directions the field should focus/ignore.\n",
    "\n",
    "\n",
    "Because the data set is relatively small (n=33), it is more useful to just manipulate this data in excel for the most part. I think the biggest applications this class has provided for this literature review is the multitude of different aesthetic plots using ggplot (although, I think I find Excel to be more intuitive for this tiny of a dataset), and the corrplot library.\n",
    "\n",
    "The corrplot tool is especially helpful in finding correlations between parameters, although for variables that are binary (such as \"Is study exploratory\", I'm not sure if the correlations are significant. If this binary dummy coding works, I'm still not sure how to integrate categorical predictors (like demographic of student) in corrplot and categorical predictors are appropriate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-- \u001b[1mAttaching packages\u001b[22m --------------------------------------- tidyverse 1.3.0 --\n",
      "\n",
      "\u001b[32mv\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.2     \u001b[32mv\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32mv\u001b[39m \u001b[34mtibble \u001b[39m 3.0.3     \u001b[32mv\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.2\n",
      "\u001b[32mv\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.1     \u001b[32mv\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32mv\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32mv\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "-- \u001b[1mConflicts\u001b[22m ------------------------------------------ tidyverse_conflicts() --\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "Warning message:\n",
      "\"package 'corrplot' was built under R version 4.0.3\"\n",
      "corrplot 0.84 loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(corrplot)\n",
    "library(stringr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eye_Move <-read.csv(\"Eye_1.csv\", header=T,na.strings=\".\") ## Why cant I get the Lgend to work correctly?\n",
    "#Eye_Move  # test to see if data loaded properly\n",
    "\n",
    "ggplot(data = Eye_Move) + \n",
    "  \n",
    "  geom_point(mapping = aes(x = ArtNum, y = AOI), color = \"blue\",size=5) +\n",
    "  geom_point(mapping = aes(x = ArtNum, y = SacLen), color = \"blue4\",size=5) +\n",
    "  geom_point(mapping = aes(x = ArtNum, y = SacNum), color = \"green\",size=5) +\n",
    "  geom_point(mapping = aes(x = ArtNum, y = FixSeq), color = \"green4\",size=5) +\n",
    "  geom_point(mapping = aes(x = ArtNum, y = FixNum), color = \"blue\",size=5) +\n",
    "  geom_point(mapping = aes(x = ArtNum, y = FixDur), color = \"red\",size=5) +\n",
    "  geom_point(mapping = aes(x = ArtNum, y = ScanPath), color = \"red4\",size=5) +\n",
    "  geom_point(mapping = aes(x = ArtNum, y = Heat), color = \"blue2\",size=5) +\n",
    "  geom_point(mapping = aes(x = ArtNum, y = Other), color = \"red2\",size=5) +\n",
    "  scale_x_continuous(breaks = seq(1, 15, 1)) +\n",
    "  scale_y_continuous(breaks = seq(1, 9, 1)) +\n",
    "\n",
    "  labs(x=\"Article Number\", y=\"Type of Eye Movement\") + \n",
    "  theme(panel.grid.minor =   element_blank(),\n",
    "  panel.grid.major =   element_line(colour = \"white\",size=0.75)) +\n",
    "  theme(axis.text=element_text(size=12),\n",
    "        axis.title=element_text(size=14,face=\"bold\"),\n",
    "        axis.text.y = element_blank())\n",
    "\n",
    "## This plot is supposed to be a representation of the type of eye movement parameters that were collected for each of the articles. \n",
    "## I had to kinda duct-tape my way around a problem - I wasn't sure how to plot more than 1 y-variable for ever x-variable.\n",
    "## For example, in article 2, I wanted to plot 1,3,4,5,6,7,and 8, but I wasnt sure how to easily have a 1-to-1 variable correlation.\n",
    "## I know that in order to make what I want plottable, I would need to turn this 14x10 data frame into a 2x70. Maybe it would be\n",
    "## a good exercise for me to try this soon, but for now, I just kinda wanted to use this as some more practice with gg plot.\n",
    "\n",
    "## Another thing that really bugged me was this y=zero row. It doesn't represent anything meaningful and I couldn't \n",
    "## remove this data with changing all 0 values to NA without getting a bunch of warnings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eye_Move_2 <- read.csv(\"Eye_2.csv\", header=T,na.strings=\".\")\n",
    "#Eye_Move_2  # test to see if data loaded properly\n",
    "\n",
    "\n",
    "EM2 <- cor(Eye_Move_2)\n",
    "corrplot(EM2, method = \"circle\",type = \"upper\")\n",
    "\n",
    "## This corrplot is a really nice tool to be able to see which paramters correlate with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Research Project Applications : Parsing Eye-tracking Data.\n",
    "\n",
    "\n",
    "Remember, the base paramaters that are collected by the eye-tracking sensors are typically:\n",
    "\n",
    "* Pupil Diameter\n",
    "* Focus x-position\n",
    "* Focus y-position\n",
    "* Time\n",
    "\n",
    "From these, we can calculate these secondary parameters:\n",
    "\n",
    "* Number of Fixations\n",
    "* Number of Saccades\n",
    "* Fixation Duration\n",
    "* Saccade Length\n",
    "* Scan Path (Order of Fixations)\n",
    "\n",
    "It is common for the software you use to already calculate all of these secondary parameters, but I thought it might be a good \n",
    "excersize for myself to try and manually figure out how to calculate a few of these.\n",
    "\n",
    "\n",
    "I found a free eye-tracking dataset from Perceptual User Interfaces -https://perceptual.mpi-inf.mpg.de/research/datasets/.\n",
    "\n",
    "In this dataset, all of the information is in just one colum within the csv file. In one cell, there are 5 pieces of information all separated by a semicolon. \n",
    "\n",
    "Here are a few things I'm trying to do to practice getting familiar with manipulating this data in r:\n",
    "\n",
    "* Separate the one column into multiple columns \n",
    "* Count the number of times a gaze has left an AOI  \n",
    "* Count the number of saccades that occured\n",
    "\n",
    "I was getting really frustrated with getting a tallier/counter to work, and unfortunately, I still don't have it working :(\n",
    "Once I get this tallier down, a lot more options open up.\n",
    "\n",
    "Anyway, here's what I got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eye_Move_3 <- read.csv(\"Eye_3.csv\", header=T,na.strings=\".\")\n",
    "\n",
    "#length(Eye_Move_3)\n",
    "\n",
    "#df <- data.frame(x = c(NA, \"a?b\", \"a.d\", \"b:c\"))\n",
    "\n",
    "Eye_Move_3 <- separate(Eye_Move_3, Data, c(\"Pup_x\", \"Pup_y\", \"Time\",\"Conf\",\"Pup_d\"), sep = \";\") ##This is seriously the only line I needed to write to separate out the values? This took me hors :(\n",
    "\n",
    "\n",
    "#str_split_fixed(Eye_Move_3$Data, \";\", Inf )\n",
    "#Eye_Move_3\n",
    "#class(Eye_Move_3)\n",
    "#typeof(Eye_Move_3)\n",
    "#names(Eye_Move_3)\n",
    "#attributes(Eye_Move_3)\n",
    "#length(Eye_Move_3)\n",
    "\n",
    "#names(Eye_Move_3)[1] <- \"Pup x\"\n",
    "#names(Eye_Move_3)\n",
    "#names(Eye_Move_3)[2] <- \"Pup y\"\n",
    "#names(Eye_Move_3)[3] <- \"Time\"\n",
    "#names(Eye_Move_3)[4] <- \"Conf\"\n",
    "#names(Eye_Move_3)[5] <- \"Pup d\"\n",
    "#names(Eye_Move_3)\n",
    "#colnames(Eye_Move_3) <- c(\"x_pup\",\"y_pup\",\"time\",\"con\",\"pup_d\")\n",
    "\n",
    "#head(Eye_Move_3, n=10L)\n",
    "\n",
    "##All of this commented out section was me trying to manipulate the names of the columns before figuring out the one line solution.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Lets say now I'd like to add a new column, which counts the number of saccades that have appeared.\n",
    "## I know from the Readme file that from left to right, the columns are (x pupil position, y pupil position, timestamp (s), confidence, and pupil diameter)\n",
    "\n",
    "## Lets say we want to calulate how many times the particpant looked outside of a defined area of interest\n",
    "## and lets define the areas of interest(AOI) where we split the screen vertically, at x=0.5, and everything on the right half \n",
    "## of the screen is outside of the AOI.\n",
    "\n",
    "Eye_Move_3$Right <- Eye_Move_3[['Pup_x']] >= 0.5 ##This adds a column, which states if pupil position is on the right or left side of screen.\n",
    "#Eye_Move_3\n",
    "\n",
    "Eye_Move_3$Right [Eye_Move_3$Right == \"true\"] <- 1  ##This replaces the boolean value from the above line, and turns it into either a 1 or 0 value.\n",
    "Eye_Move_3$Right [Eye_Move_3$Right == \"false\"] <- 0\n",
    "Eye_Move_3$Right <- as.integer(as.logical(Eye_Move_3$Right))\n",
    "\n",
    "\n",
    "#Now I'm trying to make a counter, that counts how many times the particpants gaze exited the AOI (left side of the screen)\n",
    "#i=1\n",
    "#Eye_Move_3 %>% mutate(Tally = ifelse(Right < lag(Right), i, i+1)) #If the colum \"right\" goes from 0 to 1, then the particpant went from the left side of the screen to the right. So I'd like to add one to the value in this column.\n",
    "\n",
    "#for (row in 1:nrow(Eye_Move_3)) {\n",
    "    #i=0,\n",
    "    \n",
    "    #Tally <- i\n",
    "    #ifelse(Right < lag(Right), i, i+1))\n",
    "    \n",
    "\n",
    "Eye_Move_3 %>% mutate(Tally = ifelse(Right < lag(Right), i, i+1))  \n",
    "\n",
    "\n",
    "## Eye_Move_3$Distance <- sqrt((Eye_Move_3[['Pup_x']]-lag(Eye_Move_3[['Pup_x']])^2 +(Eye_Move_3[['Pup_y']]-lag(Eye_Move_3[['Pup_y']])^2)\n",
    "\n",
    "## This is supposed to calulate the distance the eyes have moved, by taking the \n",
    "## sqrt(((current x position)-(previous x position))^2 - ((current y position)-(previous y position))^2)\n",
    "\n",
    "## It was working earlier, but I'm not sure why it just stopped working now that I'm testing it again. I must have tweaked something :(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
